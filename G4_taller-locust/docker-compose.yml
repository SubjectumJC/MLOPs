version: "3.9"

services:
  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    command: >
      mlflow server
      --backend-store-uri sqlite:///mlflow.db
      --default-artifact-root /mlflow/artifacts
      --host 0.0.0.0
    ports:
      - "5000:5000"
    volumes:
      - ./mlruns:/mlflow/artifacts
      - ./mlflow.db:/mlflow/mlflow.db
    networks:
      - mlops

  api:
    image: msaintarmand/fastapi-inferencia:latest
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    ports:
      - "8000:8000"
    depends_on:
      - mlflow
    networks:
      - mlops
    command: >
      bash -c "python train_penguin.py && uvicorn main:app --host 0.0.0.0 --port 8000"

  locust:
    image: locustio/locust
    ports:
      - "8089:8089"
    volumes:
      - ./locustfile.py:/mnt/locust/locustfile.py
    working_dir: /mnt/locust
    networks:
      - mlops
    depends_on:
      - api
    command: >
      -f locustfile.py --host http://api:8000

networks:
  mlops:
