{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proyecto MLOPS - Proyecto 1\n",
    "\n",
    "He preparado este notebook para llevar a cabo el flujo solicitado:\n",
    "1. Verifico o descargo el dataset CoverType en formato comprimido (55 columnas).\n",
    "2. Exploro brevemente el dataset y hago selección de características con scikit-learn.\n",
    "3. Construyo un pipeline TFX:\n",
    "   - Ingesta (CsvExampleGen).\n",
    "   - Estadísticas (StatisticsGen) y visualización (TFDV).\n",
    "   - Esquema (SchemaGen) e inferencia de tipos, luego curación manual.\n",
    "   - Reimportación del esquema (ImportSchemaGen).\n",
    "   - Validación de datos (ExampleValidator).\n",
    "   - (Opcional) Transform para ingeniería de características.\n",
    "4. Reviso artefactos con ML Metadata (MLMD).\n",
    "Este código está escrito como si fuera mi propio cuaderno de trabajo, con descripciones\n",
    "de cada paso para que quede documentado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Ajusto rutas para encontrar config y src\n",
    "PROJECT_ROOT = Path.cwd().parent  # notebooks/ => raíz del proyecto\n",
    "CONFIG_DIR = PROJECT_ROOT / \"config\"\n",
    "SRC_DIR = PROJECT_ROOT / \"src\"\n",
    "\n",
    "sys.path.append(str(CONFIG_DIR))\n",
    "sys.path.append(str(SRC_DIR))\n",
    "\n",
    "# Importo las rutas definidas en paths.py\n",
    "from paths import DATA_PATH, PIPELINE_ROOT, METADATA_PATH\n",
    "\n",
    "print(\"DATA_PATH      =\", DATA_PATH)\n",
    "print(\"PIPELINE_ROOT  =\", PIPELINE_ROOT)\n",
    "print(\"METADATA_PATH  =\", METADATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Exploración y Selección de Características\n",
    "\n",
    "Cargo el CSV comprimido en un DataFrame de pandas. Este dataset tiene 55 columnas:\n",
    "- 54 features (10 numéricas, 4 binarias de Wilderness, 40 binarias de Soil Types).\n",
    "- 1 columna de etiqueta (Cover_Type).\n",
    "Uso `SelectKBest(chi2)` para ejemplificar la selección de 6 características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "# Leo el CSV sin encabezado (porque es la forma en que viene)\n",
    "df = pd.read_csv(DATA_PATH, compression='gzip', header=None)\n",
    "\n",
    "print(\"Dimensiones del dataset:\", df.shape)\n",
    "# Normalmente: 581,012 filas x 55 columnas\n",
    "# - Columnas 0..53 => features\n",
    "# - Columna 54 => etiqueta\n",
    "\n",
    "# Separo X e y asumiendo que la última columna es Cover_Type\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "print(\"Ejemplo de filas:\")\n",
    "display(df.head(5))\n",
    "\n",
    "# Aplico chi2 para seleccionar, por ejemplo, 6 columnas con mayor relevancia estadística según este criterio.\n",
    "\n",
    "selector = SelectKBest(score_func=chi2, k=6)\n",
    "selector.fit(X, y)\n",
    "\n",
    "mask = selector.get_support()\n",
    "selected_cols = [i for i, m in enumerate(mask) if m]\n",
    "print(\"Columnas seleccionadas (índices):\", selected_cols)\n",
    "\n",
    "# Podría usar las columnas seleccionadas en futuros modelos. Esto sirve para ver cómo reducir dimensionalidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pipeline TFX\n",
    "\n",
    "Voy a crear un contexto interactivo para ejecutar componentes uno a uno, almacenando artefactos y registros en la ruta que definí en `PIPELINE_ROOT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.v1.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
    "\n",
    "context = InteractiveContext(\n",
    "    pipeline_root=str(PIPELINE_ROOT),\n",
    "    project_name=\"mlops_proyecto1\",\n",
    "    metadata_connection_config=None  # Por defecto, crea SQLite en pipeline_root\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Ingesta: CsvExampleGen\n",
    "TFX convierte los CSV a TFRecords. Le paso la carpeta donde está el CSV comprimido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.v1.components import CsvExampleGen\n",
    "\n",
    "DATA_DIR = DATA_PATH.parent  # la carpeta data/\n",
    "example_gen = CsvExampleGen(input_base=str(DATA_DIR))\n",
    "context.run(example_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Estadísticas: StatisticsGen\n",
    "Genero estadísticas para las divisiones `train` y `eval` automáticas que TFX hará (por defecto 2/3 y 1/3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.v1.components import StatisticsGen\n",
    "\n",
    "statistics_gen = StatisticsGen(\n",
    "    examples=example_gen.outputs['examples']\n",
    ")\n",
    "context.run(statistics_gen)\n",
    "\n",
    "\n",
    "# Verifico los artefactos generados y uso TFDV para visualizar la división `train`.\n",
    "import tensorflow_data_validation as tfdv\n",
    "from tfx.v1.types import artifact_utils\n",
    "import os\n",
    "\n",
    "stats_uri = artifact_utils.get_single_uri(\n",
    "    context.get_output_artifacts(statistics_gen)[statistics_gen.outputs['statistics']]\n",
    ")\n",
    "train_stats = tfdv.load_statistics(os.path.join(stats_uri, 'train', 'stats_tfrecord'))\n",
    "\n",
    "tfdv.visualize_statistics(train_stats, stats_title=\"Estadísticas (Train)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Inferencia de Esquema: SchemaGen\n",
    "TFX infiere automáticamente los tipos y rangos. Luego lo curaré manualmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.v1.components import SchemaGen\n",
    "\n",
    "schema_gen = SchemaGen(\n",
    "    statistics=statistics_gen.outputs['statistics'],\n",
    "    infer_feature_shape=True\n",
    ")\n",
    "context.run(schema_gen)\n",
    "\n",
    "# Cargamos el esquema resultante y lo mostramos.\n",
    "\n",
    "schema_artifact_dir = artifact_utils.get_single_uri(\n",
    "    context.get_output_artifacts(schema_gen)[schema_gen.outputs['schema']]\n",
    ")\n",
    "schema_path = os.path.join(schema_artifact_dir, 'schema.pbtxt')\n",
    "\n",
    "schema = tfdv.load_schema_text(schema_path)\n",
    "tfdv.display_schema(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Curación del Esquema\n",
    "\n",
    "Ajusto las columnas principales según el conocimiento de CoverType:\n",
    "- Columnas 0..9 son numéricas (Elevation, Aspect, etc.). \n",
    "  - Ejemplo: Slope [0..90], Hillshade9am [0..255].\n",
    "- Columnas 10..13 => Wilderness (binarias). \n",
    "- Columnas 14..53 => Soil Type (binarias). \n",
    "- Columna 54 => Cover_Type (etiqueta), valores 1..7; la marco como categórica.\n",
    "Al final, guardo el esquema “curado” en `PIPELINE_ROOT/curated_schema.pbtxt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.v1.proto import schema_pb2\n",
    "\n",
    "# Ejemplo: supongamos que la última columna se nombra \"feature_54\"\n",
    "# y la 6 es \"feature_6\" (Hillshade9am), etc.\n",
    "# Lo ideal sería renombrar las columnas antes, pero aquí muestro la idea.\n",
    "\n",
    "import tensorflow_data_validation as tfdv\n",
    "\n",
    "# # Ejemplo (si supiera a qué \"feature_N\" corresponde):\n",
    "# feat_slope = tfdv.get_feature(schema, \"feature_2\")  # Slope\n",
    "# tfdv.set_domain(feat_slope, schema_pb2.IntDomain(min=0, max=90))\n",
    "#\n",
    "# feat_hill9 = tfdv.get_feature(schema, \"feature_6\")  # Hillshade9am\n",
    "# tfdv.set_domain(feat_hill9, schema_pb2.IntDomain(min=0, max=255))\n",
    "#\n",
    "# # Declarar la última como categórica (Cover_Type):\n",
    "# feat_label = tfdv.get_feature(schema, \"feature_54\")\n",
    "# tfdv.set_domain(feat_label, schema_pb2.IntDomain(min=1, max=7))\n",
    "# feat_label.int_domain.is_categorical = True\n",
    "\n",
    "curated_schema_path = str((PIPELINE_ROOT / \"curated_schema.pbtxt\").resolve())\n",
    "tfdv.write_schema_text(schema, curated_schema_path)\n",
    "print(\"Esquema curado guardado en:\", curated_schema_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. ImportSchemaGen y nuevas Estadísticas\n",
    "Reimporto el archivo `.pbtxt` para que TFX lo reconozca como artefacto, y vuelvo a correr StatisticsGen con el esquema curado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.v1.components import ImportSchemaGen\n",
    "\n",
    "import_schema_gen = ImportSchemaGen(schema_file=curated_schema_path)\n",
    "context.run(import_schema_gen)\n",
    "\n",
    "stats_gen_curated = StatisticsGen(\n",
    "    examples=example_gen.outputs['examples'],\n",
    "    schema=import_schema_gen.outputs['schema']\n",
    ")\n",
    "context.run(stats_gen_curated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6. Validación de Anomalías: ExampleValidator\n",
    "Compara los datos con el esquema para detectar valores fuera de rango, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.v1.components import ExampleValidator\n",
    "\n",
    "example_validator = ExampleValidator(\n",
    "    statistics=stats_gen_curated.outputs['statistics'],\n",
    "    schema=import_schema_gen.outputs['schema']\n",
    ")\n",
    "context.run(example_validator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7. Transform (Opcional)\n",
    "Si quiero hacer ingeniería de características (por ejemplo, normalizar Elevation), defino un `preprocessing_fn` en un archivo Python y lo paso a `module_file`. Aquí lo dejaré en blanco como demostración.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.v1.components import Transform\n",
    "\n",
    "transform = Transform(\n",
    "    examples=example_gen.outputs['examples'],\n",
    "    schema=import_schema_gen.outputs['schema'],\n",
    "    module_file=''  # Ruta a un archivo con preprocessing_fn si existiera\n",
    ")\n",
    "try:\n",
    "    context.run(transform)\n",
    "except Exception as e:\n",
    "    print(\"Transform no se ejecutó (probablemente no definí module_file).\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Seguimiento de Artefactos (ML Metadata)\n",
    "MLMD guarda información de cada componente y artefacto. Puedo examinar la DB para ver qué se generó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.orchestration.portable import metadata\n",
    "\n",
    "store = metadata.Metadata(store_uri=str(METADATA_PATH))\n",
    "\n",
    "artifact_types = store.store.get_artifact_types()\n",
    "print(\"Artifact Types en ML Metadata:\")\n",
    "for at in artifact_types:\n",
    "    print(\" -\", at.name)\n",
    "\n",
    "# Podría, por ejemplo, listar los artefactos de tipo `Schema`:\n",
    "\n",
    "schemas = store.store.get_artifacts_by_type('Schema')\n",
    "for s in schemas:\n",
    "    print(f\"Schema ID={s.id}, URI={s.uri}, State={s.state}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Conclusiones\n",
    "\n",
    "1. **Dataset**: 581,012 filas x 55 columnas. Ultima columna = etiqueta (Cover_Type).  \n",
    "2. **Selección de características**: Ejemplo con `SelectKBest(chi2, k=6)`.  \n",
    "3. **Pipeline TFX**:  \n",
    "   - **ExampleGen** (ingesta).  \n",
    "   - **StatisticsGen** (estadísticas).  \n",
    "   - **SchemaGen** (esquema base), curado manual.  \n",
    "   - **ImportSchemaGen** (esquema definitivo).  \n",
    "   - **ExampleValidator** (validación de anomalías).  \n",
    "   - (Opcional) **Transform**.  \n",
    "4. **ML Metadata**: Uso `store_uri=str(METADATA_PATH)` para ver los artefactos.\n",
    "Con esto se demuestra cómo **manipular** este conjunto de datos en TFX, cumpliendo los pasos del taller.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
